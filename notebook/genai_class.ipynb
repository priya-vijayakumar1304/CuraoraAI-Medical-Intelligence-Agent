{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff692c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_core.messages import HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de44d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PRIYA\\OneDrive\\Desktop\\Say Yes\\CuraoraAI-Medical Intelligence Agent\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**Machine learning (ML)** is a subfield of artificial intelligence (AI) that focuses on building systems that can learn from data, improve their performance over time, and make predictions or decisions without being explicitly programmed for every possible scenario.\\n\\n### Core Idea\\n- **Learning from Data:** Instead of writing explicit rules (e.g., “if temperature\\u202f>\\u202f30°C then turn on the fan”), we provide a computer with examples (historical temperature readings and whether the fan was turned on). The algorithm discovers patterns and creates a model that can generalize to new, unseen situations.\\n- **Improvement Over Time:** As more data become available, the model can be retrained or updated, often leading to better accuracy or more robust behavior.\\n\\n### How It Works (High‑Level Steps)\\n\\n| Step | Description |\\n|------|-------------|\\n| **1. Data Collection** | Gather raw data relevant to the problem (e.g., images, text, sensor readings). |\\n| **2. Data Preparation** | Clean, normalize, and transform data (handle missing values, encode categories, split into training/validation/test sets). |\\n| **3. Model Selection** | Choose an algorithm (e.g., linear regression, decision tree, neural network) that matches the task and data characteristics. |\\n| **4. Training** | Feed the training data to the algorithm; it adjusts internal parameters to minimize a loss (error) function. |\\n| **5. Evaluation** | Test the trained model on unseen data to gauge performance (accuracy, precision, recall, RMSE, etc.). |\\n| **6. Deployment & Monitoring** | Integrate the model into an application, monitor its predictions, and periodically retrain with new data. |\\n\\n### Main Types of Machine Learning\\n\\n| Category | Learning Signal | Typical Tasks | Example Algorithms |\\n|----------|----------------|--------------|--------------------|\\n| **Supervised Learning** | Labeled data (input\\u202f+\\u202fdesired output) | Classification, regression | Logistic regression, Support Vector Machines, Random Forests, Neural Networks |\\n| **Unsupervised Learning** | Unlabeled data (only inputs) | Clustering, dimensionality reduction, anomaly detection | K‑means, DBSCAN, Principal Component Analysis (PCA), Autoencoders |\\n| **Semi‑Supervised Learning** | Small amount of labeled data + large unlabeled set | Improves performance when labeling is expensive | Self‑training, graph‑based methods |\\n| **Reinforcement Learning** | Interaction with an environment + reward signal | Decision‑making, control, game playing | Q‑learning, Deep Q‑Network (DQN), Proximal Policy Optimization (PPO) |\\n| **Self‑Supervised Learning** | Predict part of the data from other parts (no explicit labels) | Pre‑training large models (e.g., language models) | Masked language modeling (BERT), contrastive learning (SimCLR) |\\n| **Transfer Learning** | Reuse knowledge from a source task/domain for a target task/domain | Reduces data requirements, speeds up training | Fine‑tuning a pretrained ResNet for a new image classification task |\\n\\n### Common Applications\\n\\n| Domain | Example Use‑Cases |\\n|--------|-------------------|\\n| **Computer Vision** | Image classification, object detection, facial recognition, medical imaging analysis |\\n| **Natural Language Processing (NLP)** | Sentiment analysis, machine translation, chatbots, summarization |\\n| **Speech & Audio** | Speech‑to‑text, voice assistants, music recommendation |\\n| **Finance** | Fraud detection, credit scoring, algorithmic trading |\\n| **Healthcare** | Disease prediction, drug discovery, personalized treatment recommendations |\\n| **Robotics & Autonomous Systems** | Path planning, grasping objects, self‑driving cars |\\n| **Recommendation Systems** | Product suggestions on e‑commerce sites, movie/music recommendations |\\n| **Manufacturing & IoT** | Predictive maintenance, quality control, sensor anomaly detection |\\n\\n### Key Concepts & Terminology\\n\\n- **Feature:** An individual measurable property or characteristic used as input (e.g., age, pixel intensity).\\n- **Label/Target:** The output we want to predict (e.g., “spam” vs. “not spam”).\\n- **Model:** The mathematical representation learned from data (e.g., a set of weights in a neural network).\\n- **Loss Function:** Quantifies how far predictions are from true values; training aims to minimize this.\\n- **Overfitting vs. Underfitting:** Overfitting = model memorizes training data and fails on new data; underfitting = model is too simple to capture patterns.\\n- **Regularization:** Techniques (L1/L2 penalties, dropout, early stopping) to prevent overfitting.\\n- **Cross‑validation:** Splitting data multiple ways to reliably estimate model performance.\\n- **Hyperparameters:** Settings that control the learning process (e.g., learning rate, tree depth) and are tuned outside the training loop.\\n\\n### Simple Example: Predicting House Prices (Supervised Regression)\\n\\n1. **Data:** Each house is described by features like size (sq\\u202fft), number of bedrooms, location, age, etc., and a target price.\\n2. **Model Choice:** Linear regression (simple) or gradient‑boosted trees (more powerful).\\n3. **Training:** The algorithm learns coefficients that map features to price, minimizing the mean squared error between predicted and actual prices.\\n4. **Evaluation:** Use a held‑out test set; compute RMSE (root‑mean‑square error) or R² (coefficient of determination).\\n5. **Deployment:** The model can be embedded in a web service that estimates price for a new listing.\\n\\n### Getting Started (Practical Steps)\\n\\n1. **Learn the Basics:** Familiarize yourself with Python, NumPy, pandas, and basic statistics.\\n2. **Explore a Library:** Start with scikit‑learn for classical algorithms; later explore TensorFlow or PyTorch for deep learning.\\n3. **Hands‑On Projects:**  \\n   - *Titanic survival prediction* (classification)  \\n   - *MNIST digit recognition* (image classification)  \\n   - *Sentiment analysis on movie reviews* (NLP)\\n4. **Study the Theory:** Understand concepts like bias‑variance trade‑off, gradient descent, and probabilistic foundations.\\n5. **Stay Updated:** Follow conferences (NeurIPS, ICML, CVPR) and blogs (Distill, OpenAI, DeepMind) for the latest advances.\\n\\n---\\n\\n**In a nutshell:** Machine learning is the science of enabling computers to learn patterns from data, allowing them to make predictions, classify information, or take actions without being manually programmed for each specific task. It powers many of the intelligent features we encounter daily—from voice assistants and recommendation engines to medical diagnostics and autonomous vehicles.', additional_kwargs={'reasoning_content': 'The user asks \"What is machine learning?\" Simple definition. Provide concise explanation, maybe examples, types, applications. No disallowed content. Provide thorough answer.'}, response_metadata={'token_usage': {'completion_tokens': 1438, 'prompt_tokens': 76, 'total_tokens': 1514, 'completion_time': 2.995554095, 'prompt_time': 0.002880276, 'queue_time': 0.050481644, 'total_time': 2.998434371}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_213abb2467', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--951f9d75-0297-4e86-8430-42f2b3f6c9b2-0', usage_metadata={'input_tokens': 76, 'output_tokens': 1438, 'total_tokens': 1514})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"openai/gpt-oss-120b\")\n",
    "response = llm.invoke(\"What is machine learning?\")\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f418f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a:int,b:int)->int:\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc706764",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools([add])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e79d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"What is 2 plus 3\", name=\"Lance\" )])\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96cb0e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'reasoning_content': 'The user asks: \"What is 2 plus 3, call the tool\". So we need to call the add function with a=2, b=3. Then respond with result.', 'tool_calls': [{'id': 'fc_a7d23959-e6d0-4bca-9bb4-61d9e8aa7268', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 127, 'total_tokens': 200, 'completion_time': 0.14845631, 'prompt_time': 0.005792227, 'queue_time': 0.049841403, 'total_time': 0.154248537}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_ed9190d8b7', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c5007f53-f1b1-403d-a59b-8ff848ba47d1-0', tool_calls=[{'name': 'add', 'args': {'a': 2, 'b': 3}, 'id': 'fc_a7d23959-e6d0-4bca-9bb4-61d9e8aa7268', 'type': 'tool_call'}], usage_metadata={'input_tokens': 127, 'output_tokens': 73, 'total_tokens': 200})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call2 = llm_with_tools.invoke([HumanMessage(content=f\"What is 2 plus 3, call the tool\", name=\"Lance\" )])\n",
    "tool_call2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9864aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ee90ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='2\\u202f+\\u202f3\\u202f=\\u202f5.', additional_kwargs={'reasoning_content': 'User asks a simple arithmetic: 2+3 = 5. No need to call function.'}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 123, 'total_tokens': 163, 'completion_time': 0.085148287, 'prompt_time': 0.005085036, 'queue_time': 0.047782004, 'total_time': 0.090233323}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_ed9190d8b7', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--f3803ca9-ee8c-45f3-9020-4168fce3dd61-0', usage_metadata={'input_tokens': 123, 'output_tokens': 40, 'total_tokens': 163})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb68686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extentions import "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
